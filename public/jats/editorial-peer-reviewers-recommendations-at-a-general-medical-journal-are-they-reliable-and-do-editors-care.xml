<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"
                  "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
</journal-title-group>
<issn></issn>
<publisher>
<publisher-name></publisher-name>
</publisher>
</journal-meta>
<article-meta>
<title-group>
<article-title>Editorial Peer Reviewers’ Recommendations at a General
Medical Journal: Are They Reliable and Do Editors Care?</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<string-name>Martin Fenner</string-name>
</contrib>
</contrib-group>
<pub-date pub-type="epub" iso-8601-date="2010-04-12">
<day>12</day>
<month>4</month>
<year>2010</year>
</pub-date>
</article-meta>
</front>
<body>
<fig>
  <graphic mimetype="image" mime-subtype="png" xlink:href="https://web.archive.org/web/20120611094155im_/http://www.researchblogging.org/public/citation_icons/rb2_large_gray.png" xlink:title="" />
</fig>
<p>Peer review is central to how we evaluate science and therefore how
journal papers, grants and jobs are awarded. Peer review is done in many
different ways, and has dramatically changed in the last 25 years. But
the purpose of peer review is still to improve the quality of research
by providing feedback, and to evaluate the quality of research. The
evaluation serves as a filter both for limited resources (e.g. grants or
jobs; publication in a journal is no longer a limited resource), and for
other researchers to focus on the most relevant work in their field.</p>
<p>It is therefore surprising that relatively little research on peer
review itself has been done. Most discussions focus on the shortcomings
of peer review, and the arguments are often based on personal experience
and/or interests. Good research on peer review can help to improve the
peer review process. Last week such a paper was published in
<italic><italic>PLoS ONE.</italic></italic></p>
<fig>
  <caption><p>Flickr image by Gideon Burton.</p></caption>
  <graphic mimetype="image" mime-subtype="jpeg" xlink:href="https://web.archive.org/web/20120611094155im_/http://farm4.static.flickr.com/3093/3157621454_902378aa2f_d.jpg" xlink:title="" />
</fig>
<p><bold><bold>Richard Kravitz</bold></bold> and colleagues looked at
the recommendations of peer reviewers, and how they influenced the
editorial decision to publish or reject a paper. The study looked at
6213 manuscripts received 2004-2008 at the <italic><italic>Journal of
General Internal Medicine (JGIM)</italic></italic> where four of the
authors were either current or former editors in chief.</p>
<fig>
  <graphic mimetype="image" mime-subtype="jpeg" xlink:href="https://web.archive.org/web/20120611094155im_/http://www.wiley.com/bw/content/BPL_Images/Journal_Banners/JGI/JGI_large.jpg" xlink:title="" />
</fig>
<p>At <italic><italic>JGIM</italic></italic> submitted manuscripts were
first screened by an editor in chief and a deputy editor. Most
manuscripts were rejected at this step, 2264 manuscripts (36%) were sent
out for peer review. 2916 reviewers wrote a total of 5581 reviews (1-4
per manuscript) which included comments and a recommendation. Eventually
43% of the manuscripts were accepted for publication.</p>
<p>Overall, there was agreement between all reviewers in just over half
of the manuscripts (54.6% ), furthermore editors did not follow these
recommendations in another 10% of manuscripts:</p>
<fig>
  <graphic mimetype="image" mime-subtype="" xlink:href="https://web.archive.org/web/20120611094155im_/http://www.plosone.org/article/fetchObjectAttachment.action?uri=info%3Adoi%2F10.1371%2Fjournal.pone.0010072.t001&amp;representation=PNG_M" xlink:title="" />
</fig>
<p><bold><bold>Table 1. Likelihood of Initial Decision to Reject in
Relation to Reviewer Agreement.</bold></bold></p>
<p>The inter-reviewer agreement was slightly higher than what would have
been expected by chance, and was lower than the agreement between
recommendations for several manuscripts by the same reviewer. In
contrast, there was little correlation between editorial decisions for
different manuscripts handled by the same editor.</p>
<p>The authors write in the discussion:</p>
<p><italic><italic>If reviewers cannot regularly agree on whether to
recommend rejection or further consideration, the marginal contribution
of such summative recommendations may be small, and worse, they may
distract from reviewers' primary contribution, which is to improve the
reporting – and ultimately the performance – of
science.</italic></italic></p>
<p>The paper authors consider the following to improve reviewer
recommendations: using more reviewers per manuscript, providing better
training for reviewers, or recommendations could be dropped altogether
and reviewers asked to focus instead on evaluating the strengths and
weaknesses of manuscripts. Some journals are obviously using this latter
approach.</p>
<p>Several studies
<ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20120611094155/http://dx.doi.org/10.1097/01.ede.0000254668.63378.32">have
shown</ext-link> that most rejected manuscripts will eventually be
published somewhere else. One important reason is that publication space
in journals is no longer a scarcity as it was before electronic
publishing became widespread. This means that the ultimate decision
whether or not something will be published in a peer-reviewed journal
rests with the authors and not the editors or reviewers. Reviewers
should keep this in mind.</p>
<sec id="references">
  <title>References</title>
  <p>Kravitz, R., Franks, P., Feldman, M., Gerrity, M., Byrne, C., &amp;
  Tierney, W. (2010). Editorial Peer Reviewers' Recommendations at a
  General Medical Journal: Are They Reliable and Do Editors Care?
  <italic>PLoS ONE, 5</italic> (4)
  https://doi.org/<ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20120611094155/http://dx.doi.org/10.1371/journal.pone.0010072">10.1371/journal.pone.0010072</ext-link></p>
  <p><bold><bold>Further reading:</bold></bold>
  *
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20120611094155/http://www.nasw.org/users/mslong/2010/2010_04/PeerReview.htm">Questioning
  the Value of Recommendations in Peer Review</ext-link> (Michael Long)
  *
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20120611094155/http://bit.ly/9YUs0q">Scrap
  peer review and beware of top journals</ext-link> (Richard Smith)
  *
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20120611094155/http://cameronneylon.net/blog/peer-review-what-is-it-good-for/">Peer
  review: What is it good for?</ext-link> (Cameron Neylon)
  *
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20120611094155/http://backreaction.blogspot.com/2010/04/peer-review-vi.html">Peer
  Review VI</ext-link> (Sabine Hossenfelder)
  *
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20120611094155/http://blogs.nature.com/mfenner/2009/07/13/the-value-of-peer-review">The
  value of peer review</ext-link> (me)</p>
</sec>
</body>
<back>
</back>
</article>
