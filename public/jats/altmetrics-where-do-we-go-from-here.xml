<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"
                  "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">
<front>
<journal-meta>
<journal-id></journal-id>
<journal-title-group>
</journal-title-group>
<issn></issn>
<publisher>
<publisher-name></publisher-name>
</publisher>
</journal-meta>
<article-meta>
<title-group>
<article-title>Altmetrics – Where Do We Go From Here?</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<string-name>Martin Fenner</string-name>
</contrib>
</contrib-group>
<pub-date pub-type="epub" iso-8601-date="2012-01-24">
<day>24</day>
<month>1</month>
<year>2012</year>
</pub-date>
</article-meta>
</front>
<body>
<p>The
<ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://scienceonline2012.com/">ScienceOnline2012</ext-link>
conference last week again was a wonderful experience. This was my third
time in North Carolina, and I had many great conversations in the
sessions, hallways – and bars. One of many highlights was a lunch
meeting with fellow PLoS bloggers and staffers:</p>
<fig>
  <caption><p>Flickr photo by
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://www.flickr.com/photos/brian_and_dawn/">briandcrawford</ext-link>.</p></caption>
  <graphic mimetype="image" mime-subtype="jpeg" xlink:href="https://web.archive.org/web/20161027000038im_/http://farm8.staticflickr.com/7146/6732330879_726113a81d.jpg" xlink:title="" />
</fig>
<p>Together with
<ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://twitter.com/Stew">Euan
Adie</ext-link> I moderated a session on Friday:</p>
<sec id="using-altmetrics-tools-to-track-the-scholarly-impact-of-your-research-">
  <title>Using altmetrics tools to track the scholarly impact of your
  research.</title>
  <p>We started the session by asking several people in the audience to
  demonstrate their altmetrics tools:
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://altmetric.com/">altmetric.com</ext-link>
  (Euan Adie),
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://readermeter.org/">ReaderMeter</ext-link>
  (Dario Taraborelli),
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://total-impact.org/">Total
  Impact</ext-link> (Jason Priem),
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://article-level-metrics.plos.org/">PLoS
  Article-Level Metrics</ext-link> (Jennifer Lin), and
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://sciencecard.org/">ScienceCard</ext-link>
  (me). We briefly showed our
  <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://crowdometer.org/">CrowdoMeter</ext-link>
  project where we crowdsourced the meaning of tweets about scholarly
  papers.</p>
  <p>The discussion covered many interesting aspects. I would like to
  focus on three of them.</p>
  <sec id="gaming">
    <title>Gaming</title>
    <p>Altmetrics are still fairly new, and therefore not many people
    try to the cheat yet (but almost 1% of tweets in the
    <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://crowdometer.org/ratings">CrowdoMeter
    dataset</ext-link> were already spam). I’m sure that this will
    change over time, and some metrics will be more prone to gaming than
    others. Gaming is a particular problem for usage stats, as it is
    difficult to impossible to verify them. Metrics provided by the
    producer of a research object (author or publisher) will be more
    susceptible to gaming than metrics from an independent source.
    Anonymous metrics (e.g. Mendeley readers) are more susceptible to
    gaming than metrics that list the source of every citation (e.g.
    CiteULike bookmarks).</p>
  </sec>
  <sec id="context">
    <title>Context</title>
    <p>Altmetrics is currently at a stage where we collect various
    metrics, but don’t really know what these numbers mean. Does 1,000
    downloads, 10 Mendeley bookmarks or 50 tweets mean that the paper
    has impact? And how do we compare altmetrics from different
    disciplines? Does it make a difference if a
    <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://www.mathunion.org/general/prizes/fields/details/">Fields
    Medalist</ext-link> blogs about your paper (an example given in the
    session)? I think that the most interesting metrics are those that
    take into account who is citing the work, being it a regular
    citation, a social bookmark or a social media comment. This is of
    course how Google
    <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://de.wikipedia.org/wiki/PageRank">PageRank</ext-link>
    works for webpages, and how
    <ext-link ext-link-type="uri" xlink:href="https://web.archive.org/web/20161027000038/http://www.eigenfactor.org/">Eigenfactor</ext-link>
    ranks scholarly journals. The context can be further improved by
    including the social networks of the person looking for information,
    e.g. how many people I follow on Twitter have bookmarked this
    particular paper.</p>
  </sec>
  <sec id="scope">
    <title>Scope</title>
    <p>The tools discussed in the ScienceOnline session all have a
    particular approach for gathering altmetrics: altmetrics over a
    given time period (<italic>altmetric.com</italic>), altmetrics for
    content produced by a particular publisher (<italic>PLoS
    ALM</italic>), altmetrics for a given researcher
    (<italic>ReaderMeter</italic> and <italic>ScienceCard</italic>), and
    altmetrics produced for a given dataset on demand
    (<italic>Total-Impact</italic>). One obvious advantage of this
    approach is that it reduces the number of datasets needed to run the
    service. Unfortunately this is an arbitrary distinction, and it
    falls apart when you use a PageRank approach and also look at the
    metrics of citing sources.</p>
  </sec>
  <sec id="conclusions">
    <title>Conclusions</title>
    <p>I think that altmetrics has made tremendous progress in 2011, but
    that there is a lot of work to do in 2012. I’m very interested in
    altmetrics based on PageRank, but also want to take social networks
    into consideration. This is of course how finding information on the
    web works – scholarly communication is just a subset. Unfortunately
    this approach requires a massive database of scholarly citations,
    something that is impossible to do for the small part-time
    altmetrics projects mentioned at the beginning of the post.</p>
    <p>I’m less interested in usage metrics because they are so prone to
    gaming and will probably become problematic in a few years, and I
    want to focus on a reasonable number of altmetrics. I hope that
    there will never be a single “altmetric”, but I also don’t think
    that we need 20 different altmetrics for every scholarly work. A lot
    of interesting work ahead for my ScienceCard project.</p>
    <p>I’m looking forward to the altmetrics session at
    ScienceOnline2013.</p>
  </sec>
</sec>
</body>
<back>
</back>
</article>
